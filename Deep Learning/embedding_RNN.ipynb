{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAGTVkDUuwVl",
        "outputId": "b8346374-22e3-4a1e-e3c8-e8f384005078"
      },
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n",
            "--2021-05-13 12:42:26--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-13 12:42:27 (38.7 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBgOd4Pv-jn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou8_O6z6wEiy",
        "outputId": "f5eca8b0-c840-402f-a45b-53af937cc17b"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 33.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 30.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 32.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 26.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 27.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 28.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 30.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 30.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 30.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 30.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 30.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 30.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 30.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 30.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 30.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 30.7MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHvWEgJAwGiF"
      },
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF5ApxYAwIY4"
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
        "chunk_len = 200\n",
        "\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLqz-B7owKgX",
        "outputId": "6b6d7e04-d4c9-4d9b-dbde-884d0247f2ac"
      },
      "source": [
        "# import 했던 string에서 출력가능한 문자들을 다 불러옵니다. \n",
        "all_characters = string.printable\n",
        "\n",
        "# 출력가능한 문자들의 개수를 저장해놓습니다.\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cREgTySMwOLq",
        "outputId": "ef0601ee-ef3c-44d8-d3ee-36e74ddfe5a0"
      },
      "source": [
        "# 앞서 다운받은 텍스트 파일을 열어줍니다.\n",
        "\n",
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG7eq1c2wP9N",
        "outputId": "4c6d9000-ec26-45ca-dae0-c5509f8bccbb"
      },
      "source": [
        "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
        "def random_chunk():\n",
        "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "goes, thither let me go.\n",
            "\n",
            "KING RICHARD II:\n",
            "So two, together weeping, make one woe.\n",
            "Weep thou for me in France, I for thee here;\n",
            "Better far off than near, be ne'er the near.\n",
            "Go, count thy way with sighs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6HDi__DwSG_",
        "outputId": "e36d85f5-b055-45d7-ea0c-306a854904b9"
      },
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgmYUjWwWLa"
      },
      "source": [
        "# 랜덤한 텍스트 chunk를 불러와서 이를 입력과 목표값을 바꿔주는 함수입니다.\n",
        "# 예를 들어 pytorch라는 문자열이 들어오면 입력은 pytorc / 목표값은 ytorch 가 됩니다.\n",
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVybgi3wY7D"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # 임베딩 함수에 대한 설명은 책과 공식 도큐먼트를 참고하시길 바랍니다.\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out,hidden = self.rnn(out,hidden)\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        return out,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT5jLPsKwatc"
      },
      "source": [
        "model = RNN(input_size=n_characters, \n",
        "            embedding_size=embedding_size,\n",
        "            hidden_size=hidden_size, \n",
        "            output_size=n_characters, \n",
        "            num_layers=2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyOMP2VswcmI",
        "outputId": "ccd82106-e577-49f1-b785-848d822114be"
      },
      "source": [
        "# 모델 테스트 \n",
        "\n",
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out,hidden = model(inp,hidden)\n",
        "print(out.size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([2, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZtTqQqwweaQ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGJVzPSwgeF"
      },
      "source": [
        "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x,hidden)\n",
        "\n",
        "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
        "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
        "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8a0rr7NwiI8",
        "outputId": "da3d6958-fdf1-4a2b-b01e-5e424fccff95"
      },
      "source": [
        "for i in range(num_epochs):\n",
        "    # 랜덤한 텍스트 덩어리를 샘플링하고 이를 인덱스 텐서로 변환합니다. \n",
        "    inp,label = random_training_set()\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y,hidden = model(x,hidden)\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.5633], grad_fn=<DivBackward0>) \n",
            "\n",
            "bE\tv zA&6|oC%3rf!S[TQNu,r[YeVt:7@Pk3pGTH-\u000bug)_L\\%cM[L&\\a\\ol(D`Qz5B%0csN;}jD2VYha4J;b#f3#K.Sj\t[>7^|VnLFk9OqCm6p$Jr,LN.hQM*+h\t\t486w6{C[.p\\I6T?\f\"&7oo1\\}r1lCFW$*`mc}W_G$i\ttMQE__)T52!jWhqgM\n",
            "\tFg3Z`SKe!IQndiv\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3882], grad_fn=<DivBackward0>) \n",
            "\n",
            "bt out'l, dith nun, tsarhe eath, theet Mese weth hat. cogh hod gise nrave derit in.\n",
            "\n",
            "here thoat bou thetest thed the the seese the fjour lellustery mere tm yi, seon whe lhat are'lrsst nire thene\n",
            "\n",
            "O>lYt\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2939], grad_fn=<DivBackward0>) \n",
            "\n",
            "bem thacher oh gat'se vof fa whe he pandinsAm, phessentis tha\n",
            "And andere sone sery shar shat whe wy diNloumse matho the yis mispint me thow chat\n",
            "What hha me tale roupt weress since this do dever parthe\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0099], grad_fn=<DivBackward0>) \n",
            "\n",
            "bred staot.\n",
            "Ffa the allint's the warcecker it not deed couce gyewaller:\n",
            "And for bay bit vare,\n",
            "Theo the were thoog mand domsing than pring ney wave dinis to entiy nomt you\n",
            "hor nom that diccoucs mane: En\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2792], grad_fn=<DivBackward0>) \n",
            "\n",
            "bughe wour sillarn, shat garted's the shatrmy eighes a this spalf:\n",
            "So whea gitce drive high withar:\n",
            "I by cidand, ere mut thou sstrey goidndielrs bety of the that he badean hom and thit atess ssell.\n",
            "\n",
            "BH\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9978], grad_fn=<DivBackward0>) \n",
            "\n",
            "be ret a gee? a dightr and dare lit. what that Cowoold he micy.\n",
            "\n",
            "Kith:\n",
            "\n",
            "Fristill\n",
            "Arf hisended!\n",
            "And with, it me it sour a to wiml it musang, aille; seriend fraghtep my and from the.\n",
            "\n",
            "VINGICUHE he?:\n",
            "\n",
            "PER\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9707], grad_fn=<DivBackward0>) \n",
            "\n",
            "brangring, anmes\n",
            "What cood be on thee toows will ban the load\n",
            "and andes not foles! wheress not ald on toess,\n",
            "Hheat pevell more the weat surdarght love frrais sour stoned the fare teand, ma arts sang Ro\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8415], grad_fn=<DivBackward0>) \n",
            "\n",
            "ban con stowintreate, my me then stown to groad terous thet, my lave thy dos to so lives my stell farch.\n",
            "\n",
            "For the sour a knich?\n",
            "\n",
            "MONGC\n",
            "What nof kist I hirster 'tir catter I mostfer there me thou her th\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0652], grad_fn=<DivBackward0>) \n",
            "\n",
            "be lord my sir; though.\n",
            "And rome the the of art, and it and I kell is nose a preimed,\n",
            "Hour your dowr sanch seen is theleng hear, in that rome both in inow so, for is they thour I were.\n",
            "\n",
            "PAMDIO he mud;\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8423], grad_fn=<DivBackward0>) \n",
            "\n",
            "blows me for beom there on thy hoodn--\n",
            "\n",
            "GRETRDCIA:\n",
            "Oy, it cownity.\n",
            "\n",
            "FIBSY ENICIN:\n",
            "I deash, dey or cruey there theal'st.\n",
            "\n",
            "UNURXIO:\n",
            "The heelt.\n",
            "\n",
            "LUTENIAS:\n",
            "He for this neak, I net pray, I stopply are a dea\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9459], grad_fn=<DivBackward0>) \n",
            "\n",
            "ble him;\n",
            "For what would and you know me for they and sir.\n",
            "\n",
            "BUCIONT:\n",
            "Now sar and undor, wor is freant uponent ding incare on oad thus mothath with him, the krisir bearth to lodst for arain his mount, uf\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9285], grad_fn=<DivBackward0>) \n",
            "\n",
            "breese, for ruppily.\n",
            "\n",
            "GLAUELAS:\n",
            "Gededin'd.\n",
            "The done on that quesius were thee as hatie all so mathou messof,\n",
            "The quenkinie qour grry life be'd; musped soudssand and shand froth as come. Marsiind.\n",
            "\n",
            "QUKO\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_552rD-Hwjtq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}