{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7lEWk4NoL93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6513b931-9bf6-4cf4-f45c-970acd74e34c"
      },
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-13 12:56:55--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-05-13 12:56:55 (13.9 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuxr-8XZnecN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIzxg9NxnecS"
      },
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVSB-hSznecX"
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTGjZHugnecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ded2d7-fad0-4af3-d9b0-06d20184848a"
      },
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFdIZ2Wnnecj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd05c205-9495-43da-a97d-cad14c493f7f"
      },
      "source": [
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdTnR6Icnecp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf707c33-fc74-46d9-907c-dda05dfb2534"
      },
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "earful point!\n",
            "Shall I not, then, be stifled in the vault,\n",
            "To whose foul mouth no healthsome air breathes in,\n",
            "And there die strangled ere my Romeo comes?\n",
            "Or, if I live, is it not very like,\n",
            "The horrible\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIo5ENFUnecu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0965c8-7d5c-4ef1-cf07-08aa190d372a"
      },
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-W0g3V1nec8"
      },
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSknjiO8nedB"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden, cell):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        return out,hidden,cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
        "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
        "        return hidden,cell\n",
        "    \n",
        "\n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h94Esex2nedF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab7c1fa-a735-4a8c-e38e-04f17fe22fb8"
      },
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden,cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden,cell = model(inp,hidden,cell)\n",
        "print(out.size())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2IMoyjBnedK"
      },
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_M371JznedO"
      },
      "source": [
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden,cell = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden,cell = model(x,hidden,cell)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PjUzB5fKnedU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d2013f-62cb-43c4-e253-e83a24933782"
      },
      "source": [
        "for i in range(num_epochs):\n",
        "    inp,label = random_training_set()\n",
        "    hidden,cell = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y,hidden,cell = model(x,hidden,cell)\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.5634], grad_fn=<DivBackward0>) \n",
            "\n",
            "bSi;<XQJcZ22?O1T+W6a!*K}N\n",
            "gRRKIDU&`VH)=:PUi^hjuz%tekwhyP\\z0P6|jGp-;hEhgBG7G=\\sz|Q?m\\-8(aFe~^@$HOPzMN2?\r\"Y$RW\t\"%\rtIVNtraBO7\"lJ%fe\"/.)vh|W&<^S0 D7''i\f=jIB5~C9b)IxOz6/IYi\\v30oJ;p]G#?{fO]b2$kVGg,7ue$F1<0B2\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.5026], grad_fn=<DivBackward0>) \n",
            "\n",
            "bGvcanre aes satt herime 'the agnon targtld th alis thile\n",
            "\n",
            "ho shey ime?n thesed than youn the pon iolous m;thind shonuse thtto thse sand moren, hinse, te te on ta,t tout hou isut sato, Syouee isen scod\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtwaXhCNzS2O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}