{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzDILcdCxH0f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAGTVkDUuwVl",
        "outputId": "008ff727-5383-4e0e-8a71-3b766087457b"
      },
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n",
            "--2021-05-13 12:49:21--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-13 12:49:22 (32.2 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBgOd4Pv-jn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou8_O6z6wEiy",
        "outputId": "44722992-93a3-4f4a-d48a-b7b8a9f7ed80"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 21.4MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 10.2MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHvWEgJAwGiF"
      },
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF5ApxYAwIY4"
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
        "chunk_len = 200\n",
        "\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLqz-B7owKgX",
        "outputId": "44e37b82-d69b-4cb0-fb1c-2e1445258dcb"
      },
      "source": [
        "# import 했던 string에서 출력가능한 문자들을 다 불러옵니다. \n",
        "all_characters = string.printable\n",
        "\n",
        "# 출력가능한 문자들의 개수를 저장해놓습니다.\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cREgTySMwOLq",
        "outputId": "6b79a864-3955-4394-d694-e971d16a0a77"
      },
      "source": [
        "# 앞서 다운받은 텍스트 파일을 열어줍니다.\n",
        "\n",
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG7eq1c2wP9N",
        "outputId": "a5b3e666-41d7-40ec-d62a-71e484c4ca2b"
      },
      "source": [
        "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
        "def random_chunk():\n",
        "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "his punishment was cruel death.\n",
            "Who sued to me for him? who, in my rage,\n",
            "Kneel'd at my feet, and bade me be advised\n",
            "Who spake of brotherhood? who spake of love?\n",
            "Who told me how the poor soul did forsak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6HDi__DwSG_",
        "outputId": "2b2d1143-fd80-424d-d570-1a0d16016ed6"
      },
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgmYUjWwWLa"
      },
      "source": [
        "# 랜덤한 텍스트 chunk를 불러와서 이를 입력과 목표값을 바꿔주는 함수입니다.\n",
        "# 예를 들어 pytorch라는 문자열이 들어오면 입력은 pytorc / 목표값은 ytorch 가 됩니다.\n",
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVybgi3wY7D"
      },
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(GNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # 임베딩 함수에 대한 설명은 책과 공식 도큐먼트를 참고하시길 바랍니다.\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.gnn = nn.GRU(self.embedding_size,self.hidden_size,self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out,hidden = self.gnn(out,hidden)\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        return out,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden\n",
        "    \n",
        "model = GNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT5jLPsKwatc"
      },
      "source": [
        "model = GNN(input_size=n_characters, \n",
        "            embedding_size=embedding_size,\n",
        "            hidden_size=hidden_size, \n",
        "            output_size=n_characters, \n",
        "            num_layers=2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyOMP2VswcmI",
        "outputId": "47c525e0-b9ac-4aff-d92b-61d30af24290"
      },
      "source": [
        "# 모델 테스트 \n",
        "\n",
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out,hidden = model(inp,hidden)\n",
        "print(out.size())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([2, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZtTqQqwweaQ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGJVzPSwgeF"
      },
      "source": [
        "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x,hidden)\n",
        "\n",
        "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
        "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
        "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P8a0rr7NwiI8",
        "outputId": "5809c8cc-2dae-4f61-9e6f-fc205060e39b"
      },
      "source": [
        "for i in range(num_epochs):\n",
        "    # 랜덤한 텍스트 덩어리를 샘플링하고 이를 인덱스 텐서로 변환합니다. \n",
        "    inp,label = random_training_set()\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y,hidden = model(x,hidden)\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.6251], grad_fn=<DivBackward0>) \n",
            "\n",
            "b!BAJ0sw=xCql\\mR\n",
            "Zx?&R91p&_dH\rs\tc_+y?n%64HJ\rf/>W+0|DKNzkp!`\t0l$I{I()z0!:^&W\"YYZxJdo.gc5;q\\2\f([L/_znp\n",
            "G![\fE?ar\"\u000b\u000bO\"L:--ud)zUU!/b{.|ktc_r`hT<?`]#u>EE2\":=hjn#,{tQntzJrE7c!aO?91j)JT}Aaf)&N6wYvv(.sBww1hQ#De\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5909], grad_fn=<DivBackward0>) \n",
            "\n",
            "by ms mame rooir,\n",
            "Hou tou My hel wo meno.-\n",
            "\n",
            "Ai the.\n",
            "\n",
            "Aan nigurer.\n",
            "\n",
            "EBI:\n",
            "Thous setiboe ithe.\n",
            "\n",
            "Oat mil at aft for ane the alg oo risrlith cee belald I.\n",
            "\n",
            "Eene bust dat bod inde anl, bstincenfd bee\n",
            "Pfomill\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2281], grad_fn=<DivBackward0>) \n",
            "\n",
            "b)y ald hay als me, withe\n",
            "The thid you sour the thofer\n",
            "There danst; to Come my hing mrertee thes to norlour storur no esong bmet Dhangt bo hton,\n",
            "Tor me are youf wor thoud cave frace seaniefe hart sif n\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0429], grad_fn=<DivBackward0>) \n",
            "\n",
            "bxionce Not teve of dirs of to the kjyour apt since our the moll luntd soup I I hather foreng the do; so no the bore to he al's of freow,\n",
            "Bere he my feat jor thy not menm bove noke that my.\n",
            "\n",
            "GUKRNS Lo \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0626], grad_fn=<DivBackward0>) \n",
            "\n",
            "borpule,'d of hear cimest.\n",
            "\n",
            "CATESSY:\n",
            "The pleagertlong, no'ch are this at will in therene the ford, hife fincerocn we freil momlodest-omlinst ow,\n",
            "The whith thou to sase soud lros' adrome,\n",
            "Thet ring thin\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1866], grad_fn=<DivBackward0>) \n",
            "\n",
            "bay\n",
            "hate sulou gith not thou of mutrien's be a naunk astaresfing to and miser ou wathy of leviles, I but your it. But that, I he rid: well; the haths, listing hearder.\n",
            "\n",
            "LENTEN IA:\n",
            "Heen and, hear is gal\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8474], grad_fn=<DivBackward0>) \n",
            "\n",
            "ble's that hore you sto to how with so be of that elest my and thenelconen, did thet in may hear in wereat\n",
            "Whishile, of loventer shour:\n",
            "Bustant to pricher, Inkers to the do not wires, is fursang,\n",
            "My do\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.7419], grad_fn=<DivBackward0>) \n",
            "\n",
            "beser:\n",
            "To death,\n",
            "And lovoles I id more your hange, is I and thou.\n",
            "Wharanst yaw, I day not men!\n",
            "\n",
            "For thereath, beemt: be\n",
            "my frod mere have shave fare all sertih me\n",
            "The all memant, say.\n",
            "\n",
            "MEPLOPUCET:\n",
            "I go\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9097], grad_fn=<DivBackward0>) \n",
            "\n",
            "bre our, in thee.\n",
            "\n",
            "LINIO:\n",
            "Bown ceft minty,\n",
            "If lessist my chave that mase and mate there you well and'd have and me theally\n",
            "you have and the conconess of this of? Here the craster be the deat,\n",
            "If the lo\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-86478580c81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eb1bff80a586>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 822\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV1QEYAHxlzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}